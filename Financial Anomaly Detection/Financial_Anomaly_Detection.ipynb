{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "QLX5oWryfe3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"devondev/financial-anomaly-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "df=pd.read_csv(path+'/financial_anomaly_data.csv')\n",
        "df.dropna(inplace= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "999QZEhJfh8J",
        "outputId": "28b8818f-bca9-4053-801a-b56582d83927"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/devondev/financial-anomaly-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.92M/2.92M [00:01<00:00, 2.50MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/devondev/financial-anomaly-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "UwK8kqbuDJIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature: TransactionCount\n",
        "transaction_count = df.groupby('AccountID')['TransactionID'].count()\n",
        "df['TransactionCount'] = df['AccountID'].map(transaction_count)\n",
        "\n",
        "# Feature: MeanAmount\n",
        "mean_amount = df.groupby('AccountID')['Amount'].mean()\n",
        "df['MeanAmount'] = df['AccountID'].map(mean_amount)\n",
        "\n",
        "# Feature: StdAmount\n",
        "std_amount = df.groupby('AccountID')['Amount'].std().fillna(0)\n",
        "df['StdAmount'] = df['AccountID'].map(std_amount)\n",
        "\n",
        "# Feature: UniqueMerchants\n",
        "unique_merchants = df.groupby('AccountID')['Merchant'].nunique()\n",
        "df['UniqueMerchants'] = df['AccountID'].map(unique_merchants)\n",
        "\n",
        "# Feature: ActiveDays\n",
        "df['TransactionDate'] =pd.to_datetime(df['Timestamp'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
        "active_days = df.groupby('AccountID')['TransactionDate'].nunique()\n",
        "df['ActiveDays'] = df['AccountID'].map(active_days)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l_pTUCLf2YU",
        "outputId": "42b01077-991a-4613-b700-934827c2fc50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Timestamp TransactionID AccountID    Amount   Merchant  \\\n",
            "0  01-01-2023 08:00       TXN1127      ACC4  95071.92  MerchantH   \n",
            "1  01-01-2023 08:01       TXN1639     ACC10  15607.89  MerchantH   \n",
            "2  01-01-2023 08:02        TXN872      ACC8  65092.34  MerchantE   \n",
            "3  01-01-2023 08:03       TXN1438      ACC6     87.87  MerchantE   \n",
            "4  01-01-2023 08:04       TXN1338      ACC6    716.56  MerchantI   \n",
            "\n",
            "  TransactionType     Location  TransactionCount    MeanAmount     StdAmount  \\\n",
            "0        Purchase        Tokyo             14456  49623.778060  28875.132690   \n",
            "1        Purchase       London             14362  49729.927676  28797.732137   \n",
            "2      Withdrawal       London             14402  50481.295047  29290.474359   \n",
            "3        Purchase       London             14352  50038.083433  28804.031520   \n",
            "4        Purchase  Los Angeles             14352  50038.083433  28804.031520   \n",
            "\n",
            "   UniqueMerchants     TransactionDate  ActiveDays  \n",
            "0               10 2023-01-01 08:00:00       14456  \n",
            "1               10 2023-01-01 08:01:00       14362  \n",
            "2               10 2023-01-01 08:02:00       14402  \n",
            "3               10 2023-01-01 08:03:00       14352  \n",
            "4               10 2023-01-01 08:04:00       14352  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anomaly Dataset creation"
      ],
      "metadata": {
        "id": "0y1lmcpQDO9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Drop irrelevant columns\n",
        "features = df.drop(['TransactionID', 'Timestamp', 'TransactionDate'], axis=1)\n",
        "\n",
        "# Label encode categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "features['Merchant'] = label_encoder.fit_transform(features['Merchant'])\n",
        "features['TransactionType'] = label_encoder.fit_transform(features['TransactionType'])\n",
        "features['AccountID'] = label_encoder.fit_transform(features['AccountID'])\n",
        "features['Location'] = label_encoder.fit_transform(features['Location'])\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "print(scaled_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZkkDcSXf43f",
        "outputId": "a386f77a-5698-4134-d4d1-f58ba129c2fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   AccountID    Amount  Merchant  TransactionType  Location  TransactionCount  \\\n",
            "0   0.461173  1.545884  0.870183        -1.225041  1.414357         -0.080069   \n",
            "1  -1.391974 -1.185041  0.870183        -1.225041 -1.415492         -0.931569   \n",
            "2   1.387746  0.515582 -0.174726         1.228467 -1.415492         -0.569229   \n",
            "3   0.924459 -1.718415 -0.174726        -1.225041 -1.415492         -1.022154   \n",
            "4   0.924459 -1.696809  1.218485        -1.225041 -0.708030         -1.022154   \n",
            "\n",
            "   MeanAmount  StdAmount  UniqueMerchants  ActiveDays  \n",
            "0   -1.660833  -0.568613              0.0   -0.080069  \n",
            "1   -1.282714  -0.768854              0.0   -0.931569  \n",
            "2    1.393754   0.505910              0.0   -0.569229  \n",
            "3   -0.185023  -0.752557              0.0   -1.022154  \n",
            "4   -0.185023  -0.752557              0.0   -1.022154  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Train Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
        "iso_labels = iso_forest.fit_predict(scaled_df)\n",
        "\n",
        "df['IsoForest_Anomaly'] = iso_labels\n",
        "print(df['IsoForest_Anomaly'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVz_jkzbg4Jg",
        "outputId": "2e425ee8-fff3-411f-94fa-05ef46fbb891"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IsoForest_Anomaly\n",
            " 1    214795\n",
            "-1      2165\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Train DBSCAN\n",
        "dbscan = DBSCAN(eps=2, min_samples=5)\n",
        "dbscan_labels = dbscan.fit_predict(scaled_features)\n",
        "\n",
        "df['DBSCAN_Anomaly'] = dbscan_labels\n",
        "print(df['DBSCAN_Anomaly'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlAxAUugg5ay",
        "outputId": "b8146cef-ee0b-4c22-bda8-9137f7ca7642"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DBSCAN_Anomaly\n",
            " 0    86923\n",
            " 4    57662\n",
            " 2    28636\n",
            " 3    14701\n",
            " 5    14628\n",
            " 1    14400\n",
            "-1       10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Anomaly'] = (df['IsoForest_Anomaly'] == -1) | (df['DBSCAN_Anomaly'] == -1)\n",
        "anomalies = df[df['Anomaly']]\n",
        "print(f\"Total anomalies detected: {len(anomalies)}\")\n",
        "\n",
        "print(anomalies.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohmDesPkhjRI",
        "outputId": "e83529e6-3176-4355-deef-50bcc03b7917"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total anomalies detected: 2175\n",
            "            Timestamp TransactionID AccountID    Amount   Merchant  \\\n",
            "56   01-01-2023 08:56       TXN1070      ACC5  88350.57  MerchantI   \n",
            "154  01-01-2023 10:34       TXN1313      ACC5  10187.23  MerchantF   \n",
            "179  01-01-2023 10:59       TXN1546      ACC5  87677.80  MerchantA   \n",
            "425  01-01-2023 15:05        TXN962     ACC15  20576.67  MerchantA   \n",
            "427  01-01-2023 15:07       TXN1802      ACC5  12532.10  MerchantH   \n",
            "\n",
            "    TransactionType Location  TransactionCount    MeanAmount     StdAmount  \\\n",
            "56         Purchase    Tokyo             14630  50194.706156  30071.156125   \n",
            "154      Withdrawal   London             14630  50194.706156  30071.156125   \n",
            "179      Withdrawal    Tokyo             14630  50194.706156  30071.156125   \n",
            "425      Withdrawal   London             14701  50371.894606  28860.449456   \n",
            "427      Withdrawal    Tokyo             14630  50194.706156  30071.156125   \n",
            "\n",
            "     UniqueMerchants     TransactionDate  ActiveDays  IsoForest_Anomaly  \\\n",
            "56                10 2023-01-01 08:56:00       14630                 -1   \n",
            "154               10 2023-01-01 10:34:00       14630                 -1   \n",
            "179               10 2023-01-01 10:59:00       14630                 -1   \n",
            "425               10 2023-01-01 15:05:00       14701                 -1   \n",
            "427               10 2023-01-01 15:07:00       14630                 -1   \n",
            "\n",
            "     DBSCAN_Anomaly  Anomaly  \n",
            "56                5     True  \n",
            "154               5     True  \n",
            "179               5     True  \n",
            "425               3     True  \n",
            "427               5     True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anomalies.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJuNmA3DYfAo",
        "outputId": "b3c6a46f-bbea-4105-f07b-5132e9b01cbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2175, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVhowq2zLqH9",
        "outputId": "27696a9b-7659-4330-c8d9-ec1abcbebb60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Downloading mysql_connector_python-9.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (34.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.connector\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "host = 'sql12.freesqldatabase.com'\n",
        "port = 3306\n",
        "database = 'sql12759851'\n",
        "user = 'sql12759851'\n",
        "password = 'QDv4j2W7kE'\n",
        "\n",
        "try:\n",
        "    conn = mysql.connector.connect(\n",
        "        host=host,\n",
        "        port=port,\n",
        "        database=database,\n",
        "        user=user,\n",
        "        password=password\n",
        "    )\n",
        "    print(\"Successfully connected to the database!\")\n",
        "    cursor = conn.cursor()\n",
        "    print(\"Cursor created successfully!\")\n",
        "\n",
        "except mysql.connector.Error as err:\n",
        "    print(f\"Error: {err}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyBgV3E92m2f",
        "outputId": "4e94a264-90c0-40f4-d867-0e93eeb71af7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully connected to the database!\n",
            "Cursor created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}')\n"
      ],
      "metadata": {
        "id": "VX801Q8UX5Pc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save anomalies DataFrame to MySQL\n",
        "table_name = 'anomalies_detected'  # Table name\n",
        "\n",
        "try:\n",
        "    anomalies.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
        "    print(f\"DataFrame saved successfully to table '{table_name}'.\")\n",
        "except Exception as e:\n",
        "    print(\"Error saving DataFrame:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiL19bMrW7p4",
        "outputId": "56272943-2d87-4218-c1c5-985b064abaf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved successfully to table 'anomalies_detected'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify saved data\n",
        "query = f\"SELECT COUNT(Timestamp) FROM {table_name} ;\"  # Retrieve first 5 rows\n",
        "cursor.execute(query)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "for row in rows:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjST8T2gYCb9",
        "outputId": "221b2d57-b9e1-4be0-f9cb-d0faba19453f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2175,)\n"
          ]
        }
      ]
    }
  ]
}